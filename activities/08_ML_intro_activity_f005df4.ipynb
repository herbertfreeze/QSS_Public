{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised machine learning: Introduction and regularization \n",
    "## Binary classification with text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load packages \n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import plotnine\n",
    "from plotnine import *\n",
    "import pickle\n",
    "\n",
    "## nltk imports\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "## sklearn imports\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "## print mult things\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "## random\n",
    "import random\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to process text\n",
    "def processtext(one_str, stop_list):\n",
    "    \n",
    "    ## remove stopwords\n",
    "    no_stop = [tok for tok in wordpunct_tokenize(one_str)\n",
    "              if tok not in stop_list]\n",
    "    \n",
    "    \n",
    "    processed_string = \" \".join([porter.stem(i.lower()) \n",
    "                        for i in no_stop if \n",
    "                        i.lower().isalpha() and len(i) >=3])\n",
    "    return(processed_string)\n",
    "\n",
    "## function to create dtm\n",
    "def create_dtm(list_of_strings, metadata):\n",
    "    vectorizer = CountVectorizer(lowercase = True)\n",
    "    dtm_sparse = vectorizer.fit_transform(list_of_strings)\n",
    "    dtm_dense_named = pd.DataFrame(dtm_sparse.todense(), columns=vectorizer.get_feature_names_out())\n",
    "    dtm_dense_named_withid = pd.concat([metadata.reset_index(), dtm_dense_named], axis = 1)\n",
    "    return(dtm_dense_named_withid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "\n",
    "Load labeled yelp data in `public_data` and run below code\n",
    "\n",
    "**Note**: make sure to change your path if you need to; if you're having trouble loading the `pkl`, try running on jupyter hub since it may be a python versioning issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have trouble loading these data (kernel dies due to memory issues), try sampling down to 5000 or 1000 rows\n",
    "yelp = pd.read_pickle(\"../public_data/yelp_forML.pkl\") #.sample(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preprocess data to create dtm\n",
    "porter = PorterStemmer()\n",
    "list_stopwords = stopwords.words(\"english\")\n",
    "\n",
    "yelp['process_text'] = [processtext(one_review, stop_list = list_stopwords) \n",
    "                        for one_review in yelp['raw_text']]\n",
    "\n",
    "yelp_dtm = create_dtm(yelp['process_text'], yelp[['metadata_label', 'metadata_rowid',\n",
    "                                                 'process_text', 'raw_text']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Split into features, labels, and split into training/hold out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Split into X (features or id metadata) and y (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = yelp_dtm[[col for col in yelp_dtm.columns if col not in ['metadata_label',\n",
    "                                                            'index']]].copy()\n",
    "y = yelp_dtm[['metadata_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 23439)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(15000, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## checking dimensionality\n",
    "X.shape\n",
    "y.shape\n",
    "\n",
    "assert X.shape[0] == y.shape[0]\n",
    "assert y.shape[1] == 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 using automatic function to create train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### using built-in function\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                   test_size = 0.2,\n",
    "                                                   random_state = 221)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_test.values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 using more manual approach to create train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### more manually: useful when we want more control\n",
    "### over the ids (eg clustering or time ordering)\n",
    "### or if we want to go back to matrix before preprocessing\n",
    "nrows_train = round(X.shape[0]*0.8)\n",
    "nrows_test = X.shape[0] - nrows_train\n",
    "random.seed(221)\n",
    "train_ids = random.sample(list(set(X['metadata_rowid'])), nrows_train)\n",
    "\n",
    "def my_split(X, y, \n",
    "             train_ids, \n",
    "             id_col):\n",
    "    \n",
    "    ## get test ids\n",
    "    test_ids = set(X[id_col]).difference(train_ids)\n",
    "    \n",
    "    ## split\n",
    "    X_train_man = X[X[id_col].isin(train_ids)].copy()\n",
    "    X_test_man = X[X[id_col].isin(test_ids)].copy()\n",
    "    y_train_man = y[y.index.isin(train_ids)].iloc[:, 0].to_numpy()\n",
    "    y_test_man = y[y.index.isin(test_ids)].iloc[:, 0].to_numpy()\n",
    "    \n",
    "    ## return\n",
    "    return(X_train_man, X_test_man, y_train_man, y_test_man)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_man, X_test_man, y_train_man, y_test_man = my_split(X, y,\n",
    "                                                            train_ids, \n",
    "                                                            id_col = 'metadata_rowid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_man"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Estimate models with hardcoded parameters: logistic regression with L1 regularization (Lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Estimate model using training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.01, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.01, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.01, penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "non_feat = ['metadata_rowid', 'raw_text', 'process_text']\n",
    "logit_lasso = LogisticRegression(penalty = \"l1\",max_iter=100, \n",
    "             C = 0.01, solver='liblinear')\n",
    "logit_lasso.fit(X_train_man[[col for col in X_train.columns if col not in \n",
    "                   non_feat]], y_train_man)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Generate predictions in test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logit_lasso.predict(X_test_man[[col for col \n",
    "                in X_test_man.columns if col not in non_feat]])\n",
    "y_predprob = logit_lasso.predict_proba(X_test_man[[col for col \n",
    "                in X_test_man.columns if col not in non_feat]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.64279266, 0.35720734],\n",
       "       [0.69705267, 0.30294733],\n",
       "       [0.06367281, 0.93632719],\n",
       "       [0.72128942, 0.27871058],\n",
       "       [0.50402252, 0.49597748]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## print the results \n",
    "y_pred[0:5]\n",
    "y_predprob[0:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Clean up predictions and calculate error metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred_binary</th>\n",
       "      <th>y_pred_continuous</th>\n",
       "      <th>y_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>0</td>\n",
       "      <td>0.240226</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>1</td>\n",
       "      <td>0.698157</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1641</th>\n",
       "      <td>1</td>\n",
       "      <td>0.790618</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249</th>\n",
       "      <td>1</td>\n",
       "      <td>0.535206</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>0</td>\n",
       "      <td>0.448078</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2490</th>\n",
       "      <td>0</td>\n",
       "      <td>0.432704</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2857</th>\n",
       "      <td>1</td>\n",
       "      <td>0.679533</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160</th>\n",
       "      <td>1</td>\n",
       "      <td>0.681760</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>1</td>\n",
       "      <td>0.519448</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2255</th>\n",
       "      <td>0</td>\n",
       "      <td>0.193009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      y_pred_binary  y_pred_continuous  y_true\n",
       "656               0           0.240226       0\n",
       "825               1           0.698157       1\n",
       "1641              1           0.790618       1\n",
       "2249              1           0.535206       1\n",
       "1080              0           0.448078       0\n",
       "2490              0           0.432704       1\n",
       "2857              1           0.679533       1\n",
       "1160              1           0.681760       1\n",
       "1061              1           0.519448       0\n",
       "2255              0           0.193009       0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred_binary</th>\n",
       "      <th>y_pred_continuous</th>\n",
       "      <th>y_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.357153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.302924</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.936390</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.278692</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.495900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y_pred_binary  y_pred_continuous  y_true\n",
       "0              0           0.357153       0\n",
       "1              0           0.302924       0\n",
       "2              1           0.936390       1\n",
       "3              0           0.278692       0\n",
       "4              0           0.495900       0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## make into a dataframe\n",
    "y_pred_df = pd.DataFrame({'y_pred_binary': y_pred,\n",
    "                         'y_pred_continuous': [one_prob[1] \n",
    "                                            for one_prob in y_predprob],\n",
    "                         'y_true': y_test_man})\n",
    "y_pred_df.sample(n = 10, random_state = 4484)\n",
    "y_pred_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TN</td>\n",
       "      <td>1320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TP</td>\n",
       "      <td>1103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FN</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FP</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cat     n\n",
       "0  TN  1320\n",
       "1  TP  1103\n",
       "2  FN   319\n",
       "3  FP   258"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision is:-----------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8104335047759"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall is:---------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7756680731364276"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## precision as tp / tp+fp \n",
    "error_cond = [(y_pred_df['y_true'] == 1) & (y_pred_df['y_pred_binary'] == 1),\n",
    "             (y_pred_df['y_true'] == 1) & (y_pred_df['y_pred_binary'] == 0),\n",
    "              (y_pred_df['y_true'] == 0) & (y_pred_df['y_pred_binary'] == 0)]\n",
    "\n",
    "error_codeto = [\"TP\", \"FN\", \"TN\"]\n",
    "\n",
    "y_pred_df['error_cat'] = np.select(error_cond, error_codeto, default = \"FP\")\n",
    "y_error = y_pred_df.error_cat.value_counts().reset_index().copy()\n",
    "y_error.columns = ['cat', 'n']\n",
    "y_error\n",
    "\n",
    "### precision\n",
    "print(\"Precision is:-----------\")\n",
    "y_error.loc[y_error.cat == \"TP\", 'n'].iloc[0]/(y_error.loc[y_error.cat == \"TP\", 'n'].iloc[0] +\n",
    "                    y_error.loc[y_error.cat == \"FP\", 'n'].iloc[0])\n",
    "\n",
    "### recall\n",
    "print(\"Recall is:---------------\")\n",
    "y_error.loc[y_error.cat == \"TP\", 'n'].iloc[0]/(y_error.loc[y_error.cat == \"TP\", 'n'].iloc[0] +\n",
    "                    y_error.loc[y_error.cat == \"FN\", 'n'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Interpret the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0f/r6sb0yjx70l_25cgtvyjjqgr0000gn/T/ipykernel_59921/1319144360.py:12: FutureWarning: The provided callable <function mean at 0x10a5a6700> is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>delici</th>\n",
       "      <th>great</th>\n",
       "      <th>love</th>\n",
       "      <th>amaz</th>\n",
       "      <th>excel</th>\n",
       "      <th>best</th>\n",
       "      <th>favorit</th>\n",
       "      <th>friendli</th>\n",
       "      <th>definit</th>\n",
       "      <th>alway</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metadata_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.026424</td>\n",
       "      <td>0.171178</td>\n",
       "      <td>0.085976</td>\n",
       "      <td>0.022944</td>\n",
       "      <td>0.018819</td>\n",
       "      <td>0.103506</td>\n",
       "      <td>0.027713</td>\n",
       "      <td>0.067672</td>\n",
       "      <td>0.059036</td>\n",
       "      <td>0.113302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.162248</td>\n",
       "      <td>0.557305</td>\n",
       "      <td>0.284452</td>\n",
       "      <td>0.104529</td>\n",
       "      <td>0.093621</td>\n",
       "      <td>0.219691</td>\n",
       "      <td>0.116819</td>\n",
       "      <td>0.169014</td>\n",
       "      <td>0.142640</td>\n",
       "      <td>0.242613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  delici     great      love      amaz     excel      best  \\\n",
       "metadata_label                                                               \n",
       "0               0.026424  0.171178  0.085976  0.022944  0.018819  0.103506   \n",
       "1               0.162248  0.557305  0.284452  0.104529  0.093621  0.219691   \n",
       "\n",
       "                 favorit  friendli   definit     alway  \n",
       "metadata_label                                          \n",
       "0               0.027713  0.067672  0.059036  0.113302  \n",
       "1               0.116819  0.169014  0.142640  0.242613  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get top features\n",
    "las_coef = pd.DataFrame({'coef': logit_lasso.coef_[0],\n",
    "                         'feature_name': \n",
    "                        [col for col in X_train.columns if col not in non_feat]})\n",
    "\n",
    "#las_coef.sort_values(by = 'coef', ascending = False)\n",
    "\n",
    "\n",
    "top_feat = las_coef.sort_values(by = 'coef', ascending = False)[0:10]\n",
    "top_feat_list = top_feat.feature_name.to_list()\n",
    "\n",
    "all_agg = [yelp_dtm.groupby(['metadata_label']).agg({one_feat: np.mean})\n",
    "for one_feat in top_feat_list]\n",
    "\n",
    "all_agg_df = pd.concat(all_agg, axis = 1)\n",
    "all_agg_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Compare performance across hyperparameters for logistic regression\n",
    "\n",
    "Would our logit model make more accurate predictions if we fed it different hyperpameters? Which hyperparameters would be the best? Let's find out.\n",
    "\n",
    "1. Define a function that:\n",
    "- takes in a cost parameter (*C*, the inverse of regularization strength)\n",
    "- trains a logistic regression model with L1 regularization (Lasso) and otherwise has the same parameters as above\n",
    "- fits the model on the training data\n",
    "- makes predictions and returns them as a DataFrame\n",
    "\n",
    "2. Use the function to get predictions for the list of *C* parameters below, then bind them into one DataFrame.\n",
    "\n",
    "3. Finally, score the precision for each model (each iteration of *C*) and show which model scores the best.\n",
    "\n",
    "**Hint**: To compute precision score, you can use:\n",
    "```python\n",
    "precision_score(\n",
    "    one_df['y_true'], one_df['y_pred'],\n",
    "    zero_division = 0) # silences warning\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provided set of hyperparameters on which to train and then compare performance\n",
    "c_list = np.linspace(4, 0.0001, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solution:\n",
    "## define function that takes in one cost parameter\n",
    "## and estimates model, returning pred\n",
    "def one_las(C):\n",
    "    one_lasso = LogisticRegression(penalty = \"l1\", max_iter=100, \n",
    "             C = C, solver='liblinear')\n",
    "    \n",
    "    one_lasso.fit(X_train_man[[col for col in X_train.columns if \n",
    "                              col not in non_feat]], y_train_man)\n",
    "    \n",
    "    y_pred = one_lasso.predict(X_test_man[[col for col in X_test_man.columns \n",
    "                if col not in non_feat]])\n",
    "    \n",
    "    y_pred_df = pd.DataFrame({'y_pred': y_pred, \n",
    "                             'y_true': y_test_man,\n",
    "                             'cost': C})\n",
    "    return(y_pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in c_list: one_las(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make into a dataframe\n",
    "y_pred_df_1 = pd.DataFrame({'y_pred_binary': y_pred,\n",
    "                         'y_pred_continuous': [one_prob[1] \n",
    "                                            for one_prob in y_predprob],\n",
    "                         'y_true': y_test_man})\n",
    "y_pred_df_1.sample(n = 10, random_state = 4484)\n",
    "y_pred_df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## precision as tp / tp+fp \n",
    "error_cond = [(y_pred_df_1['y_true'] == 1) & (y_pred_df_1['y_pred_binary'] == 1),\n",
    "             (y_pred_df_1['y_true'] == 1) & (y_pred_df_1['y_pred_binary'] == 0),\n",
    "              (y_pred_df_1['y_true'] == 0) & (y_pred_df_1['y_pred_binary'] == 0)]\n",
    "\n",
    "error_codeto = [\"TP\", \"FN\", \"TN\"]\n",
    "\n",
    "y_pred_df_1['error_cat'] = np.select(error_cond, error_codeto, default = \"FP\")\n",
    "y_error = y_pred_df_1.error_cat.value_counts().reset_index().copy()\n",
    "y_error.columns = ['cat', 'n']\n",
    "y_error\n",
    "\n",
    "### precision\n",
    "print(\"Precision is:-----------\")\n",
    "y_error.loc[y_error.cat == \"TP\", 'n'].iloc[0]/(y_error.loc[y_error.cat == \"TP\", 'n'].iloc[0] +\n",
    "                    y_error.loc[y_error.cat == \"FP\", 'n'].iloc[0])\n",
    "\n",
    "### recall\n",
    "print(\"Recall is:---------------\")\n",
    "y_error.loc[y_error.cat == \"TP\", 'n'].iloc[0]/(y_error.loc[y_error.cat == \"TP\", 'n'].iloc[0] +\n",
    "                    y_error.loc[y_error.cat == \"FN\", 'n'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Activity \n",
    "\n",
    "- Read the documentation here to initialize a ridge regression (l2 penalty)- you can use the same cost parameter (C) and number of iterations as in the lasso example above: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "- Fit the model on X_train_man, y_train_main \n",
    "- Generate binary and continuous predictions\n",
    "- Create a function that takes in a dataframe of binary predictions and true labels and manually calculates the $F_{1}$ score:\n",
    "\n",
    "$$F_{1} = 2 * \\dfrac{precision * recall}{precision + recall} = \\dfrac{TP}{TP + 0.5(FP + FN)}$$\n",
    "\n",
    "- Apply that function to calculate the F1 score for the decision tree and lasso (from above), and ridge regression (from the activity)\n",
    "- *Challenge exercise*: parametrize the model fitting with a function that takes in a classifier as an argument and returns coefficients or feature importances and certain eval metrics (eg precision, recall, and F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=1, solver='liblinear')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here \n",
    "logit_ridge = LogisticRegression(penalty = \"l2\",max_iter=100, \n",
    "             C = 1, solver='liblinear')\n",
    "\n",
    "X_feat_tr = X_train_man[[col for col in X_train_man.columns \n",
    "                if col not in non_feat]]\n",
    "X_feat_te = X_test_man[[col for col in X_test_man.columns \n",
    "                if col not in non_feat]]\n",
    "logit_ridge.fit(X_feat_tr, y_train_man)\n",
    "## predict\n",
    "y_hat = logit_ridge.predict(X_feat_te)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_myF1(fit_classifier, X_test, y_test):\n",
    "    \n",
    "    ## predict\n",
    "    y_hat = fit_classifier.predict(X_test)\n",
    "    \n",
    "    ## get the relevant counts\n",
    "    df_pred = pd.DataFrame({'y_true': y_test,\n",
    "                           'y_pred_binary': y_hat})\n",
    "    \n",
    "    ## counts of diff metrics\n",
    "    tp = df_pred[(df_pred.y_true == 1) &\n",
    "            (df_pred.y_pred_binary == 1)].shape[0]\n",
    "    fp = df_pred[(df_pred.y_true == 0) &\n",
    "            (df_pred.y_pred_binary == 1)].shape[0]\n",
    "    fn = df_pred[(df_pred.y_true == 1) &\n",
    "            (df_pred.y_pred_binary == 0)].shape[0]\n",
    "    \n",
    "    ## combine\n",
    "    f1 = (tp)/(tp + 0.5*(fp + fn))\n",
    "    \n",
    "    ## return\n",
    "    return(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8745220716023636"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7926697808120733"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_myF1(logit_ridge, X_test = X_feat_te, y_test = y_test_man)\n",
    "calc_myF1(logit_lasso, X_test = X_feat_te, y_test = y_test_man)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>feat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005291</td>\n",
       "      <td>aaa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001103</td>\n",
       "      <td>aaaaaa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>aaaaaaaaaaaaaaand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000129</td>\n",
       "      <td>aaaaaaaaaaaaahhhhhhhhhhh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.076687</td>\n",
       "      <td>aaaaand</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       coef                      feat\n",
       "0  0.005291                       aaa\n",
       "1 -0.001103                    aaaaaa\n",
       "2  0.000004         aaaaaaaaaaaaaaand\n",
       "3  0.000129  aaaaaaaaaaaaahhhhhhhhhhh\n",
       "4 -0.076687                   aaaaand"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>feat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5009</th>\n",
       "      <td>1.862923</td>\n",
       "      <td>delici</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>1.815087</td>\n",
       "      <td>amaz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6744</th>\n",
       "      <td>1.800407</td>\n",
       "      <td>fantast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19359</th>\n",
       "      <td>1.766226</td>\n",
       "      <td>solid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6510</th>\n",
       "      <td>1.654128</td>\n",
       "      <td>excel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>-2.064684</td>\n",
       "      <td>bland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11696</th>\n",
       "      <td>-2.122132</td>\n",
       "      <td>mediocr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20768</th>\n",
       "      <td>-2.160225</td>\n",
       "      <td>terribl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23108</th>\n",
       "      <td>-2.437169</td>\n",
       "      <td>worst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9033</th>\n",
       "      <td>-2.730583</td>\n",
       "      <td>horribl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23436 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           coef     feat\n",
       "5009   1.862923   delici\n",
       "526    1.815087     amaz\n",
       "6744   1.800407  fantast\n",
       "19359  1.766226    solid\n",
       "6510   1.654128    excel\n",
       "...         ...      ...\n",
       "1880  -2.064684    bland\n",
       "11696 -2.122132  mediocr\n",
       "20768 -2.160225  terribl\n",
       "23108 -2.437169    worst\n",
       "9033  -2.730583  horribl\n",
       "\n",
       "[23436 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_c = pd.DataFrame({'coef': logit_ridge.coef_[0],\n",
    "                        'feat': X_feat_tr.columns})\n",
    "\n",
    "ridge_c[ridge_c.coef != 0].head()\n",
    "ridge_c.sort_values(by = 'coef', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test_man"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
